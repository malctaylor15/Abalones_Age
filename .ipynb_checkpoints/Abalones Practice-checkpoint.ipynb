{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First let's import some packages that might be useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sk "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next let's look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "\n",
      "   Shell weight  Rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7   \n",
      " \n",
      "              Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
      "count  4177.000000  4177.000000  4177.000000   4177.000000     4177.000000   \n",
      "mean      0.523992     0.407881     0.139516      0.828742        0.359367   \n",
      "std       0.120093     0.099240     0.041827      0.490389        0.221963   \n",
      "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
      "25%       0.450000     0.350000     0.115000      0.441500        0.186000   \n",
      "50%       0.545000     0.425000     0.140000      0.799500        0.336000   \n",
      "75%       0.615000     0.480000     0.165000      1.153000        0.502000   \n",
      "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
      "\n",
      "       Viscera weight  Shell weight        Rings  \n",
      "count     4177.000000   4177.000000  4177.000000  \n",
      "mean         0.180594      0.238831     9.933684  \n",
      "std          0.109614      0.139203     3.224169  \n",
      "min          0.000500      0.001500     1.000000  \n",
      "25%          0.093500      0.130000     8.000000  \n",
      "50%          0.171000      0.234000     9.000000  \n",
      "75%          0.253000      0.329000    11.000000  \n",
      "max          0.760000      1.005000    29.000000  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"toy_ds.csv\")\n",
    "print(data.head(), '\\n \\n ', data.describe())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Change the Sex variable to be numbers - first let's see how many unique \"Sex\"s there are \n",
    "Then we will change each one to be a number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'F' 'I']\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Sex\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data[\"Sex\"]=='M' , \"Sex\" ] = 0\n",
    "data.loc[data[\"Sex\"]=='F' , \"Sex\" ] = 1\n",
    "data.loc[data[\"Sex\"]=='I' , \"Sex\" ] = 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We want to sort based on three categories \n",
    "Young (1) - 1-8 \n",
    "Medium (2) - 9-10\n",
    "Old (3) - 11+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgeCategory\n",
      "1    1407\n",
      "2    1323\n",
      "3    1447\n",
      "dtype: int64 \n",
      " 4177\n"
     ]
    }
   ],
   "source": [
    "data[\"AgeCategory\"] = 0\n",
    "data.loc[data['Rings'] <9, \"AgeCategory\"] = 1\n",
    "data.loc[(data['Rings'] >= 9) & (data['Rings'] <= 10), \"AgeCategory\"] = 2\n",
    "data.loc[data['Rings'] >10, \"AgeCategory\" ] = 3\n",
    "print(data.groupby('AgeCategory').size(), '\\n',\n",
    "sum(data.groupby('AgeCategory').size()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For more information about the sets and save information to a variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Length</th>\n",
       "      <th>Rings</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Whole weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeCategory</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
       "      <th>count</th>\n",
       "      <td>1407.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.321276</td>\n",
       "      <td>0.106596</td>\n",
       "      <td>0.420991</td>\n",
       "      <td>6.884151</td>\n",
       "      <td>0.121394</td>\n",
       "      <td>0.198199</td>\n",
       "      <td>0.093357</td>\n",
       "      <td>0.432374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090292</td>\n",
       "      <td>0.041830</td>\n",
       "      <td>0.111375</td>\n",
       "      <td>1.216914</td>\n",
       "      <td>0.080965</td>\n",
       "      <td>0.147031</td>\n",
       "      <td>0.068090</td>\n",
       "      <td>0.306007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.082250</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>0.368500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.169750</td>\n",
       "      <td>0.282250</td>\n",
       "      <td>0.129250</td>\n",
       "      <td>0.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.565000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.825500</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>1.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2</th>\n",
       "      <th>count</th>\n",
       "      <td>1323.000000</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>1323.000000</td>\n",
       "      <td>1323.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.436754</td>\n",
       "      <td>0.148171</td>\n",
       "      <td>0.560170</td>\n",
       "      <td>9.479214</td>\n",
       "      <td>0.258777</td>\n",
       "      <td>0.416345</td>\n",
       "      <td>0.204731</td>\n",
       "      <td>0.927122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.069540</td>\n",
       "      <td>0.029392</td>\n",
       "      <td>0.085249</td>\n",
       "      <td>0.499757</td>\n",
       "      <td>0.101876</td>\n",
       "      <td>0.194768</td>\n",
       "      <td>0.091182</td>\n",
       "      <td>0.396543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.271250</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.539250</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>1.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>1.253000</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>2.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3</th>\n",
       "      <th>count</th>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.465695</td>\n",
       "      <td>0.163614</td>\n",
       "      <td>0.591068</td>\n",
       "      <td>13.314444</td>\n",
       "      <td>0.334784</td>\n",
       "      <td>0.463986</td>\n",
       "      <td>0.243350</td>\n",
       "      <td>1.124204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.068473</td>\n",
       "      <td>0.029277</td>\n",
       "      <td>0.083205</td>\n",
       "      <td>2.770863</td>\n",
       "      <td>0.130774</td>\n",
       "      <td>0.217678</td>\n",
       "      <td>0.103497</td>\n",
       "      <td>0.458919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.793500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.324500</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>1.092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>1.410500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.825500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Diameter       Height       Length        Rings  \\\n",
       "AgeCategory                                                             \n",
       "1           count  1407.000000  1407.000000  1407.000000  1407.000000   \n",
       "            mean      0.321276     0.106596     0.420991     6.884151   \n",
       "            std       0.090292     0.041830     0.111375     1.216914   \n",
       "            min       0.055000     0.000000     0.075000     1.000000   \n",
       "            25%       0.260000     0.085000     0.350000     6.000000   \n",
       "            50%       0.325000     0.105000     0.430000     7.000000   \n",
       "            75%       0.385000     0.125000     0.500000     8.000000   \n",
       "            max       0.565000     1.130000     0.720000     8.000000   \n",
       "2           count  1323.000000  1323.000000  1323.000000  1323.000000   \n",
       "            mean      0.436754     0.148171     0.560170     9.479214   \n",
       "            std       0.069540     0.029392     0.085249     0.499757   \n",
       "            min       0.205000     0.015000     0.280000     9.000000   \n",
       "            25%       0.395000     0.130000     0.515000     9.000000   \n",
       "            50%       0.450000     0.150000     0.575000     9.000000   \n",
       "            75%       0.485000     0.165000     0.620000    10.000000   \n",
       "            max       0.600000     0.515000     0.770000    10.000000   \n",
       "3           count  1447.000000  1447.000000  1447.000000  1447.000000   \n",
       "            mean      0.465695     0.163614     0.591068    13.314444   \n",
       "            std       0.068473     0.029277     0.083205     2.770863   \n",
       "            min       0.235000     0.060000     0.310000    11.000000   \n",
       "            25%       0.420000     0.145000     0.535000    11.000000   \n",
       "            50%       0.475000     0.165000     0.600000    12.000000   \n",
       "            75%       0.515000     0.185000     0.650000    15.000000   \n",
       "            max       0.650000     0.250000     0.815000    29.000000   \n",
       "\n",
       "                   Shell weight  Shucked weight  Viscera weight  Whole weight  \n",
       "AgeCategory                                                                    \n",
       "1           count   1407.000000     1407.000000     1407.000000   1407.000000  \n",
       "            mean       0.121394        0.198199        0.093357      0.432374  \n",
       "            std        0.080965        0.147031        0.068090      0.306007  \n",
       "            min        0.001500        0.001000        0.000500      0.002000  \n",
       "            25%        0.060000        0.082250        0.040000      0.196000  \n",
       "            50%        0.106500        0.165000        0.078500      0.368500  \n",
       "            75%        0.169750        0.282250        0.129250      0.597000  \n",
       "            max        0.470000        0.825500        0.385500      1.710000  \n",
       "2           count   1323.000000     1323.000000     1323.000000   1323.000000  \n",
       "            mean       0.258777        0.416345        0.204731      0.927122  \n",
       "            std        0.101876        0.194768        0.091182      0.396543  \n",
       "            min        0.040000        0.045500        0.026000      0.124000  \n",
       "            25%        0.185000        0.271250        0.139000      0.646000  \n",
       "            50%        0.259000        0.415000        0.199000      0.917500  \n",
       "            75%        0.322500        0.539250        0.264500      1.184000  \n",
       "            max        0.655000        1.253000        0.541000      2.381000  \n",
       "3           count   1447.000000     1447.000000     1447.000000   1447.000000  \n",
       "            mean       0.334784        0.463986        0.243350      1.124204  \n",
       "            std        0.130774        0.217678        0.103497      0.458919  \n",
       "            min        0.040000        0.041500        0.024000      0.120000  \n",
       "            25%        0.249000        0.299500        0.166000      0.793500  \n",
       "            50%        0.324500        0.437000        0.234000      1.092000  \n",
       "            75%        0.410000        0.598000        0.306000      1.410500  \n",
       "            max        1.005000        1.488000        0.760000      2.825500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('AgeCategory').describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Drop the Column with the rings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_use = data.drop('Rings',1)\n",
    "table1 = data_use.groupby('AgeCategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# table1['Diameter'].agg([np.mean,np.std])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we know more about our data set and it is ready to be used... lets try a multinomial logistics regression\n",
    "Start by importing the Logisitic Regression Module from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Split dataframe into input and output variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data_use.drop('AgeCategory', 1)\n",
    "Y = data_use[\"AgeCategory\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run logistic regression in various settings... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#OVR_fit = OneVsRestClassifier(LogisticRegression()).fit(X,Y)\n",
    "#OVO_fit = OneVsOneClassifier(LogisticRegression()).fit(X,Y)\n",
    "log_fit = LogisticRegression().fit(X,Y)\n",
    "print(log_fit)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Check the raw predictive accuracy of each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict_OVR = OVR_fit.predict(X)\n",
    "#predict_OVO = OVO_fit.predict(X)\n",
    "predict_log = log_fit.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.79      0.73      1407\n",
      "          2       0.51      0.37      0.43      1323\n",
      "          3       0.66      0.71      0.68      1447\n",
      "\n",
      "avg / total       0.62      0.63      0.62      4177\n",
      "\n",
      "[[1115  231   61]\n",
      " [ 361  486  476]\n",
      " [ 186  231 1030]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y,predict_log))\n",
    "print(metrics.confusion_matrix(Y, predict_log))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Logistic regression \n",
    "Not great at 63% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X,Y)\n",
    "predict_KNN = KNN.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.85      0.81      1407\n",
      "          2       0.64      0.66      0.65      1323\n",
      "          3       0.80      0.71      0.76      1447\n",
      "\n",
      "avg / total       0.74      0.74      0.74      4177\n",
      "\n",
      "[[1197  180   30]\n",
      " [ 226  872  225]\n",
      " [ 111  303 1033]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y,predict_KNN))\n",
    "print(metrics.confusion_matrix(Y, predict_KNN))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Not bad for KNN \n",
    "74 % accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(random_state=1)\n",
    "RF.fit(X,Y)\n",
    "predict_RF = RF.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.97      1.00      0.99      1407\n",
      "          2       0.98      0.97      0.98      1323\n",
      "          3       0.99      0.98      0.98      1447\n",
      "\n",
      "avg / total       0.98      0.98      0.98      4177\n",
      "\n",
      "[[1402    3    2]\n",
      " [  26 1285   12]\n",
      " [  10   21 1416]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y,predict_RF))\n",
    "print(metrics.confusion_matrix(Y, predict_RF))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I think the tree is too deep and over fitting \n",
    "I am suspicious of that 98% "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lets try ensembling with a Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomF...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))],\n",
       "         n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators = [('lr', log_fit), ('rf', RF), ('knn', KNN)], voting = 'hard')\n",
    "eclf2 = VotingClassifier(estimators = [('lr', log_fit), ('rf', RF), ('knn', KNN)], voting = 'soft')\n",
    "\n",
    "eclf1.fit(X,Y)\n",
    "eclf2.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.93      0.86      1407\n",
      "          2       0.83      0.74      0.78      1323\n",
      "          3       0.86      0.82      0.84      1447\n",
      "\n",
      "avg / total       0.83      0.83      0.83      4177\n",
      "\n",
      "[[1303   83   21]\n",
      " [ 178  973  172]\n",
      " [ 151  110 1186]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.90      0.94      0.92      1407\n",
      "          2       0.91      0.84      0.87      1323\n",
      "          3       0.91      0.93      0.92      1447\n",
      "\n",
      "avg / total       0.90      0.90      0.90      4177\n",
      "\n",
      "[[1316   60   31]\n",
      " [ 101 1115  107]\n",
      " [  51   53 1343]]\n"
     ]
    }
   ],
   "source": [
    "eclf1_predict = eclf1.predict(X)\n",
    "eclf2_predict = eclf2.predict(X)\n",
    "\n",
    "print(metrics.classification_report(Y,eclf1_predict))\n",
    "print(metrics.confusion_matrix(Y, eclf1_predict))\n",
    "\n",
    "print(metrics.classification_report(Y,eclf2_predict))\n",
    "print(metrics.confusion_matrix(Y, eclf2_predict))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let begin using cross validation on the different algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_alg = {log_fit, RF, KNN, eclf1, eclf2}\n",
    "scores = {}\n",
    "score_mean = {}\n",
    "score_sd = {}\n",
    "for alg in all_alg:\n",
    "    scores[alg] = cross_val_score(alg, X, Y, cv = 10);\n",
    "    score_mean[alg] = scores[alg].mean()\n",
    "    score_sd[alg] = scores[alg].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Statistics \n",
      "\n",
      "Mean: 0.6220 Standard Deviation: 0.0342 \n",
      "Mean: 0.6134 Standard Deviation: 0.0193 \n",
      "Mean: 0.6411 Standard Deviation: 0.0260 \n",
      "Mean: 0.6148 Standard Deviation: 0.0291 \n",
      "Mean: 0.6294 Standard Deviation: 0.0233 \n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation Statistics \\n\")\n",
    "for alg in all_alg:\n",
    "    print(\"Mean: %0.4f Standard Deviation: %0.4f \" % (scores[alg].mean(), scores[alg].std()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's try looking into the correlation structure of the sections of the data sets \n",
    "We will have to remove the sex class, seperate by age category then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  \n",
       "0         0.150  \n",
       "1         0.070  \n",
       "2         0.210  \n",
       "3         0.155  \n",
       "4         0.055  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data =  data_use.drop(['Sex', 'AgeCategory'],1)\n",
    "pca_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=7, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1 = PCA(n_components=7)\n",
    "pca1.fit(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.74100729e-01   1.14183886e-02   8.37567021e-03   3.03865180e-03\n",
      "   1.41047670e-03   1.22936128e-03   4.26722250e-04]\n"
     ]
    }
   ],
   "source": [
    "pca_score = pca1.explained_variance_ratio_\n",
    "print(pca_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First principal component explains 97% of the variance... We might only need that for the future analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37297053],\n",
       "       [-0.72693017],\n",
       "       [-0.17700541],\n",
       "       ..., \n",
       "       [ 0.41895149],\n",
       "       [ 0.34791783],\n",
       "       [ 1.31843776]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1_comp = PCA(n_components=1)\n",
    "pca_data1 = pca1_comp.fit_transform(pca_data)\n",
    "pca_data1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create a pipeline to run all the classic Classification algorithms and get the accuracy number and CV scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(random_state=1)\n",
    "RF2 = RandomForestClassifier(random_state=1)\n",
    "KNN2 = KNeighborsClassifier()\n",
    "ensemble1 = VotingClassifier(estimators = [('lr', logistic), ('rf', RF2), ('knn', KNN2)], voting = 'hard')\n",
    "ensemble2 = VotingClassifier(estimators = [('lr', logistic), ('rf', RF2), ('knn', KNN2)], voting = 'soft')\n",
    "\n",
    "alg_total2 = {logistic, RF2, KNN2, ensemble1, ensemble2}\n",
    "names = {\"Logistic Regression\", \"Random Forest\" ,\"KNN\", \"Ensemble Hard\", \"Ensemble Soft\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.95      0.80      1407\n",
      "          2       0.91      0.56      0.69      1323\n",
      "          3       0.78      0.78      0.78      1447\n",
      "\n",
      "avg / total       0.79      0.77      0.76      4177\n",
      "\n",
      "[[1335   19   53]\n",
      " [ 323  740  260]\n",
      " [ 268   56 1123]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.91      0.87      1407\n",
      "          2       0.89      0.74      0.81      1323\n",
      "          3       0.83      0.87      0.85      1447\n",
      "\n",
      "avg / total       0.85      0.84      0.84      4177\n",
      "\n",
      "[[1280   51   76]\n",
      " [ 154  982  187]\n",
      " [ 110   73 1264]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.83      0.70      1407\n",
      "          2       0.36      0.06      0.10      1323\n",
      "          3       0.51      0.73      0.60      1447\n",
      "\n",
      "avg / total       0.50      0.55      0.48      4177\n",
      "\n",
      "[[1162   54  191]\n",
      " [ 423   77  823]\n",
      " [ 305   80 1062]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.84      0.75      1407\n",
      "          2       0.60      0.55      0.57      1323\n",
      "          3       0.70      0.60      0.65      1447\n",
      "\n",
      "avg / total       0.66      0.67      0.66      4177\n",
      "\n",
      "[[1183  148   76]\n",
      " [ 304  724  295]\n",
      " [ 244  329  874]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.98      0.96      1407\n",
      "          2       0.94      0.94      0.94      1323\n",
      "          3       0.96      0.93      0.95      1447\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4177\n",
      "\n",
      "[[1376   15   16]\n",
      " [  46 1243   34]\n",
      " [  43   62 1342]]\n"
     ]
    }
   ],
   "source": [
    "for alg2 in alg_total2:\n",
    "    alg2.fit(pca_data1, Y)\n",
    "    temp_predict = alg2.predict(pca_data1)\n",
    "    print(metrics.classification_report(Y,temp_predict))\n",
    "    print(metrics.confusion_matrix(Y, temp_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_pca = {}\n",
    "score_mean_pca = {}\n",
    "score_sd_pca = {}\n",
    "for alg in alg_total2:\n",
    "    scores_pca[alg] = cross_val_score(alg, pca_data1, Y, cv = 5);\n",
    "    score_mean_pca[alg] = scores_pca[alg].mean()\n",
    "    score_sd_pca[alg] = scores_pca[alg].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Statistics \n",
      "\n",
      "Mean: 0.5265 Standard Deviation: 0.0169 \n",
      "Mean: 0.5121 Standard Deviation: 0.0191 \n",
      "Mean: 0.5511 Standard Deviation: 0.0290 \n",
      "Mean: 0.5291 Standard Deviation: 0.0142 \n",
      "Mean: 0.4798 Standard Deviation: 0.0160 \n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation Statistics \\n\")\n",
    "for alg in alg_total2:\n",
    "    print(\"Mean: %0.4f Standard Deviation: %0.4f \" % (scores_pca[alg].mean(), scores_pca[alg].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.98      0.96      1407\n",
      "          2       0.94      0.94      0.94      1323\n",
      "          3       0.96      0.93      0.95      1447\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4177\n",
      "\n",
      "[[1376   15   16]\n",
      " [  46 1243   34]\n",
      " [  43   62 1342]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.64136697801632492"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X,Y)\n",
    "lda_predict = lda.predict(X)\n",
    "print(metrics.classification_report(Y,temp_predict))\n",
    "print(metrics.confusion_matrix(Y, temp_predict))\n",
    "cross_val_score(lda,X,Y, cv = 5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.98      0.96      1407\n",
      "          2       0.94      0.94      0.94      1323\n",
      "          3       0.96      0.93      0.95      1447\n",
      "\n",
      "avg / total       0.95      0.95      0.95      4177\n",
      "\n",
      "[[1376   15   16]\n",
      " [  46 1243   34]\n",
      " [  43   62 1342]]\n",
      "0.643056800712\n"
     ]
    }
   ],
   "source": [
    "clf1 = MLPClassifier()\n",
    "clf1.fit(X,Y)\n",
    "clf1_predict = clf1.predict(X)\n",
    "print(metrics.classification_report(Y,temp_predict))\n",
    "print(metrics.confusion_matrix(Y, temp_predict))\n",
    "print(cross_val_score(clf1, X,Y,cv= 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
